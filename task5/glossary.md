# Glossary for the "Load Balancer with Service Turn-Off" project

**Allocation:** The process of resource booking for the elements of the system.

**Application scaling:** The process of adjusting the number of instances of application pods based on demand.

**Autoscaling:** A feature that automatically adjusts the number of instances of an application based on predefined rules.

**Balancing policy:** A set of rules specified for the balancing feature.

**Balancing:** A feature that distributes network traffic across multiple instances of an application

**Cluster:** A group of nodes that work together to run applications.

**Configuration (balancer configuration):** A set of rules for scaling and balancing applied to a load balancer.

**Deployment:** A process of nodes allocation or reallocation.

**Instance:** A running copy of an application.

**Kubelet:** A primary "node agent", that stores and manages meta-information  about nodes.

**Kube-Proxy:** An agent that runs on each node and manages network connections on low level.

**Kubernetes (k8s):** An open-source system for automating deployment, scaling, and management of containerized applications.

**Load balancer:** A device or software that implements balancing feature to ensure high availability and performance.

**Node:** A physical or virtual machine that runs containers.

**Observability system:** A software that allows to manage core observability metrics of a web application.

**Observability metrics:** A set of data, that indicates a state of a system.

**Pod:** The smallest deployable unit in Kubernetes, consisting of one or more containers.

**Resource:** A physical resource (CPU, RAM, Network bandwidth) used for pods allocation.

**Reallocation:** The process of repeated resource allocation.

**Scaling policy:** A set of rules specified for the autoscaling feature.

**Service:** A Kubernetes object that provides a stable network endpoint for a set of Pods.
